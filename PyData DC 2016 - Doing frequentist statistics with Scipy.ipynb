{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing frequentist statistics with Scipy  \n",
    "  \n",
    "### PyData DC 2016  \n",
    "  \n",
    "*Gustavo A. Patino*  \n",
    "*Department of Biomedical Sciences*  \n",
    "*Department of Neurology*  \n",
    "*Oakland University William Beaumont School of Medicine*  \n",
    "*Rochester, MI*  \n",
    "  \n",
    "patino@oakland.edu  \n",
    "https://github.com/gapatino/Doing-frequentist-statistics-with-Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iris Dataset:**  \n",
    "Fisher RA. The use of multiple measurements in taxonomic problems. *Annals of Eugenics* 1936; 7 (2): 179â€“188\n",
    "\n",
    "https://github.com/gapatino/Doing-frequentist-statistics-with-Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from tkinter import filedialog\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use file browser to find name and path of the CSV file that contains the dataset\n",
    "data_file = filedialog.askopenfilename()\n",
    "print(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_file, sep=',', na_values=[\".\",\" \",\"na\"]) # Can use lists for possible missing values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.describe(percentiles=[.25, .5, .75], include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_iris = dataset.groupby('Type')\n",
    "grouped_iris.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "Create a table that describes the grouped_iris data frame, including the 25th, 50th, and 75th percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_iris.describe(percentiles=[.25, .5, .75], include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_iris['Petal_Width'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, kind='reg', hue='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "For the statistical functions we will have to specify the dependent data variable and the independent data variable as two separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_iris['Type'] # .groupby function returns a GroupBy object that is lazily executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[dataset['Type']=='setosa'].head(n=10) # Better to use the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "How would you make separate variables containing the petal and sepal characteristics of each iris type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[dataset['Type']=='setosa']['Petal_Length'].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl_setosa = dataset[dataset['Type']=='setosa']['Petal_Length']\n",
    "pl_virginica = dataset[dataset['Type']=='virginica']['Petal_Length']\n",
    "pl_versicolor = dataset[dataset['Type']=='versicolor']['Petal_Length']\n",
    "\n",
    "pw_setosa = dataset[dataset['Type']=='setosa']['Petal_Width']\n",
    "pw_virginica = dataset[dataset['Type']=='virginica']['Petal_Width']\n",
    "pw_versicolor = dataset[dataset['Type']=='versicolor']['Petal_Width']\n",
    "\n",
    "sl_setosa = dataset[dataset['Type']=='setosa']['Sepal_Length']\n",
    "sl_virginica = dataset[dataset['Type']=='virginica']['Sepal_Length']\n",
    "sl_versicolor = dataset[dataset['Type']=='versicolor']['Sepal_Length']\n",
    "\n",
    "sw_setosa = dataset[dataset['Type']=='setosa']['Sepal_Width']\n",
    "sw_virginica = dataset[dataset['Type']=='virginica']['Sepal_Width']\n",
    "sw_versicolor = dataset[dataset['Type']=='versicolor']['Sepal_Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(sw_setosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(sw_versicolor, label='Versicolor', alpha=0.5)\n",
    "plt.hist(sw_virginica, label='Virginica', alpha=0.5)\n",
    "plt.hist(sw_setosa, label='Setosa', alpha=0.5)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kolmogorov-Smirnov test: Fairly conservative\n",
    "ks_pl_setosa = stats.kstest(pl_setosa, 'norm', mode='asymp') # mode opts: 'approx'. Dist can be any in scipy.stats\n",
    "ks_pl_setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shapiro test\n",
    "shapiro_pw_setosa = stats.shapiro(pw_setosa)\n",
    "shapiro_pw_setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normal test: Combines skew and kurtosis measurement. Allows management of NaN\n",
    "nt_sl_setosa = stats.normaltest(sl_setosa, nan_policy='omit') #nan_policy opts: 'propagate', 'raise'\n",
    "nt_sl_setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Anderson test: Modified KS, returns critical values for a list of significance levels\n",
    "anderson_sw_setosa = stats.anderson(sw_setosa, dist='norm')\n",
    "anderson_sw_setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "- What do the outputs mean?\n",
    "- How would you extract only the *p*-value of a given test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('KS: ', ks_pl_setosa)\n",
    "print('Shapiro: ', shapiro_pw_setosa)\n",
    "print('Normal: ', nt_sl_setosa)\n",
    "print('Anderson: ', anderson_sw_setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the outputs are the test value and associated *p*-value, except for Anderson test in which the test value is provided along with a table of critical values for given significances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('KS p-value using index: ', ks_pl_setosa[1])\n",
    "# or\n",
    "_ , p_ks_pl_setosa = stats.kstest(pl_setosa, 'norm', mode='asymp')\n",
    "print('KS p-value using multiple variable assignment: ', p_ks_pl_setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneity of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bartlett test: Requires normal populations\n",
    "bartlett_length_versicolor = stats.bartlett(pl_versicolor, sl_versicolor)\n",
    "print(bartlett_length_versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Levene test: more robust than Bartlett if samples are non-normal. Can define what central tendency measure is used\n",
    "levene_length_virginica = stats.levene(pl_virginica, sl_virginica, center='trimmed') # For heavy-tailed distributions\n",
    "print(levene_length_virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fligner-Killeen's test: Non-parametric\n",
    "fk_length_setosa = stats.fligner(pl_virginica, sl_virginica, center='mean') # For normal distributions\n",
    "                                                                            # Use 'median' for skewed distributions\n",
    "print(fk_length_setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2 samples of a continuous measure: Parametric tests   \n",
    "*t*-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t-test of 2 independent samples\n",
    "ttest_sw_set_ver = stats.ttest_ind(sw_setosa, sw_versicolor, equal_var=True, nan_policy='omit') # equal_var default: T\n",
    "print(ttest_sw_set_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t-test of paired samples\n",
    "ttest_width_setosa = stats.ttest_rel(pw_setosa, sw_setosa, nan_policy='omit')\n",
    "print(ttest_width_setosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t-test from descriptive statistics: mean, SD, n from each sample\n",
    "ttest_pw_vir_ver = stats.ttest_ind_from_stats(20.06, 2.902, 50, 13.26, 1.977, 50, equal_var=False)\n",
    "print(ttest_pw_vir_ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Effect sizes**  \n",
    "Cohen's *d*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*d* = $\\frac{x_1 - x_2}{SDp}$  \n",
    "  \n",
    "*d*=0.2 small effect size, 0.5 medium, 0.8 large    \n",
    "  \n",
    "$SD_p$ (Pooled standard deviation) = $\\sqrt[2]{\\frac{(N_1-1)(SD_1^2)+(N_2-1)(SD_2^2)}{N_1+N_2-2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "What is the value of Cohen's *d*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate pooled STD\n",
    "std_sw_set_ver = np.sqrt( ( (sw_setosa.size-1)*(sw_setosa.std()**2) + (sw_versicolor.size-1)*(sw_versicolor.std()**2) ) \n",
    "                         / (sw_setosa.size + sw_versicolor.size - 2) )\n",
    "# Calculate Cohen's d\n",
    "cohend_sw_set_ver = (sw_setosa.mean() - sw_versicolor.mean()) / std_sw_set_ver\n",
    "print('Cohen\\'s d: ', cohend_sw_set_ver) # d=0.2 small effect size, 0.5 medium, 0.8 large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's correlation coefficient can also be used as a measure of effect size (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1-stats.norm.cdf(ttest_pw_vir_ver[0]) # one-side p-value if I know the test value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.norm.ppf(ttest_pw_vir_ver[1]) # What is the test value given the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2 samples of a continuous measure: Non-Parametric tests \n",
    "Wilcoxon rank-sum  \n",
    "Mann-Whitney U  \n",
    "Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wilcoxon rank-sum test: Can use if n < 20\n",
    "wrk_sw_set_ver = stats.ranksums(sw_setosa, sw_versicolor)\n",
    "print(wrk_sw_set_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mann-Whitney U test: More robust than Wilcoxon rank-sum, use if n > 20\n",
    "mwu_sw_set_ver = stats.mannwhitneyu(sw_setosa, sw_versicolor, use_continuity=True, alternative='greater')\n",
    "                                    # alternative options: 'less', 'two-sided'. 'None' is deprecated\n",
    "print(mwu_sw_set_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wilcoxon test: For paired samples\n",
    "wilcoxon_width_setosa = stats.wilcoxon(pw_setosa, sw_setosa, zero_method='wilcox', correction=False)\n",
    "                        # zero_method is how zero-differences are handled. Options: 'pratt', 'zsplit'\n",
    "                        # correction is if statistic is corrected towards the mean during calculation. Default: F\n",
    "print(wilcoxon_width_setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing multiple groups**  \n",
    "ANOVA  \n",
    "Kruskal-Wallis H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1-way ANOVA: Parametric\n",
    "anova_sw = stats.f_oneway(sw_setosa, sw_versicolor, sw_virginica)\n",
    "print(anova_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What about post-*hoc* tests, DF, and other results?*  \n",
    "Not available in the Scipy.stats implementation  \n",
    "Use of linear regression with the **statsmodels** module allows access to some of that data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kruskal-Wallis H test: Non-parametric\n",
    "kw_sw = stats.kruskal(sw_setosa, sw_versicolor, sw_virginica, nan_policy='omit')\n",
    "print(kw_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contingency Tables   \n",
    "Chi square  \n",
    "Fisher's exact test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pd.crosstab(vector1, vector2)** creates a contingency table from two binary vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "Create a contingency table from counts of big and small petal width and sepal width using the mean as cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_pw = dataset['Petal_Width'].mean()\n",
    "mean_sw = dataset['Sepal_Width'].mean()\n",
    "\n",
    "width_table = pd.crosstab(dataset.Petal_Width > mean_pw, dataset.Sepal_Width > mean_sw)\n",
    "width_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi square: Requires a matrix composed of individual arrays or a pd.crosstab result as input \n",
    "chi2_width = stats.chi2_contingency(width_table, correction=False) # Correction: Yates'\n",
    "                                     # Another optional argument: lambda_='pearson'/'log-likelihood'/'freeman-tukey'/\n",
    "                                     # 'mod-log-likelihood'/'neyman'/'cressie-read'\n",
    "                                     # lambda_ default is None which computes Pearson's chi2\n",
    "print(chi2_width)\n",
    "print('\\n')\n",
    "print(' Chi-square value: ', chi2_width[0], '\\n',\n",
    "      'p-value: ', chi2_width[1], '\\n',\n",
    "      'Degrees of freedom: ', chi2_width[2], '\\n',\n",
    "      'Expected frequencies: ', chi2_width[3], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fisher's exact test: Use if any expected frequency is < 5\n",
    "fisher_width = stats.fisher_exact([[18,42],\n",
    "                                   [65,25]], alternative='two-sided') # alternative options: 'less', 'greater'\n",
    "print(fisher_width)\n",
    "print('\\n')\n",
    "print(' Odds ratio: ', fisher_width[0], '\\n',\n",
    "      'p-value: ', fisher_width[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation  \n",
    "Pearson's correlation coefficient *r*  \n",
    "Spearman rank-order correlation coefficient *rho*  \n",
    "Point-biserial correlation coefficient  \n",
    "Kendall's *Tau*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient: Parametric\n",
    "pearson_petal = stats.pearsonr(dataset['Petal_Width'], dataset['Petal_Length'])\n",
    "print(pearson_petal,'\\n')\n",
    "print('Pearson\\'s correlation coefficient: ', pearson_petal[0])\n",
    "print('p-value: ', pearson_petal[1]) # p-value is not so useful or reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spearman rank-order correlation coefficient: Non-parametric\n",
    "spearman_sepal = stats.spearmanr(dataset['Sepal_Width'], dataset['Sepal_Length'], nan_policy='omit')\n",
    "print(spearman_sepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Point-biserial correlation coefficient: Measures correlation between a binary and a continuous variable\n",
    "setosa_type = dataset['Type']=='setosa' #Binary variable\n",
    "pbs_setosa_sw = stats.pointbiserialr(setosa_type, dataset['Sepal_Width'])\n",
    "print(pbs_setosa_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kendall's Tau: Non-parametric. Arguments for use: Ordinal data, more robust than Spearman, non-linear relations\n",
    "ktau_versicolor = stats.kendalltau(pw_versicolor, pl_versicolor, initial_lexsort=None, nan_policy='omit') \n",
    "                  # initial_lexsort=False uses quicksort\n",
    "print(ktau_versicolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatterplot of variables to include in regression\n",
    "sns.lmplot(y='Petal_Width', x='Sepal_Width', data=dataset) # Add hue='Type' to observe subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scipy linear regression using least-squares. Only works for univariate\n",
    "scipy_linreg_width = stats.linregress(dataset['Sepal_Width'], dataset['Petal_Width']) # order of x,y != from lmplot\n",
    "print(scipy_linreg_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stats.linregress** provides limited information, and the library lacks a logistic regression function.  \n",
    "Use the **statsmodels** library for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg_width = smf.ols(formula='Petal_Width ~ Sepal_Width', data=dataset)\n",
    "reg_width_model = reg_width.fit()\n",
    "reg_width_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(reg_width_model.summary()) # This way is better to obtain warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print( dir(reg_width_model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot residuals, an important quality control step, we need to use the predict() method. This function takes as input a matrix of predictive variables plus a new column for the intercept. To create this compound matrix we need to use the add_constant() function from the other statsmodels api: **statsmodels.api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "pred_var_matrix = dataset['Sepal_Width']\n",
    "pred_var_matrix = sm.add_constant(pred_var_matrix)\n",
    "sm_reg_width = sm.OLS( dataset['Petal_Width'], pred_var_matrix) # Note the difference from smf.ols\n",
    "sm_reg_width_model = sm_reg_width.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting residuals:\n",
    "# Obtain predicted values for dependent variable\n",
    "predicted_values = reg_width_model.predict(pred_var_matrix) # dataset['Sepal_Width'] is not valid input\n",
    "sm_predicted_values = sm_reg_width_model.predict(pred_var_matrix)\n",
    "\n",
    "residuals = dataset['Petal_Width'] - sm_predicted_values\n",
    "normalized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "normalized_predicted = (sm_predicted_values - np.mean(sm_predicted_values)) / np.std(sm_predicted_values)\n",
    "\n",
    "plt.plot(normalized_residuals, normalized_predicted, 'o')\n",
    "plt.xlabel('Standardized Residuals')\n",
    "plt.ylabel('Standardized Predicted Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence = sm_reg_width_model.get_influence()\n",
    "influence_dbetas = influence.summary_frame().filter(regex='dfb')\n",
    "print(influence_dbetas.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFBeta measures the influence a given sample exerts over the model. The maximum value allowed can be calculated as:  \n",
    "$2^{\\sqrt{N}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "Find if any sample exerts an excessive influence over our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence_max = 2**(np.sqrt(sm_reg_width_model.nobs)) \n",
    "print('Maximum value of DFBeta: ', influence_max)\n",
    "any(influence_dbetas['dfb_Sepal_Width'] > influence_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logregr_setosa_sw = sm.Logit(setosa_type, pred_var_matrix)\n",
    "logregr_setosa_sw_model = logregr_setosa_sw.fit()\n",
    "print(logregr_setosa_sw_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate odds ratio\n",
    "print(np.exp(logregr_setosa_sw_model.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  \n",
    "Plot the data against the values predicted by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predicted values vs. data\n",
    "logregr_predicted_values = logregr_setosa_sw_model.predict(pred_var_matrix)\n",
    "plt.plot(dataset['Sepal_Width'], setosa_type, 'o')\n",
    "plt.plot(dataset['Sepal_Width'], logregr_predicted_values,'ok')\n",
    "plt.xlabel('Sepal Width')\n",
    "plt.ylabel('Setosa type')\n",
    "plt.ylim(-0.05, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
